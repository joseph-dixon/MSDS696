{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "319c84d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/josephdixon/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     /Users/josephdixon/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import wordpunct_tokenize\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pymongo\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import string\n",
    "from tensorflow.keras.preprocessing.text import one_hot\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.layers import Dense, Embedding, AveragePooling1D, Conv1D, Flatten, GlobalMaxPooling1D\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ed22fa3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to DB\n",
    "client = pymongo.MongoClient(\"mongodb://localhost:27017/\")\n",
    "mydb = client[\"msds696\"]\n",
    "mycol = mydb[\"climate_score_corpus\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8d6f5e09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load results into DataFrame\n",
    "results = mycol.find()\n",
    "df =  pd.DataFrame(list(results))\n",
    "del df['_id']\n",
    "\n",
    "df = df[df.label != 'Test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "80f4ef2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(corpus):\n",
    "    # Remove stopwords\n",
    "    tokens = wordpunct_tokenize(corpus)\n",
    "    tokens = [w.lower() for w in tokens] # Lowercase letters\n",
    "    table = str.maketrans('', '', string.punctuation) # Remove punctuation\n",
    "    stripped = [w.translate(table) for w in tokens]\n",
    "    words = [word for word in stripped if word.encode().isalpha()] # Keep only English text\n",
    "    stop_words = set(stopwords.words('english')) # Remove English stopwords\n",
    "    words = [w for w in words if not w in stop_words]\n",
    "\n",
    "    # Lemmatize\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    corpus_cleaned = [lemmatizer.lemmatize(word) for word in words]\n",
    "    corpus_cleaned = ' '.join(corpus_cleaned)\n",
    "    return corpus_cleaned\n",
    "\n",
    "df['corpus_cleaned'] = df['corpus'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8ff23bf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     environmental policy joe biden administration ...\n",
      "1     pete buttigieg transportation climate solution...\n",
      "2     climate change senator edward markey massachus...\n",
      "3     green new deal bernie sander official website ...\n",
      "4     climate representative ocasio cortez skip main...\n",
      "5     combatting climate crisis congresswoman diana ...\n",
      "6     energy environment governor jay inslee skip ma...\n",
      "7     climate justice michelle wu bostonskip main co...\n",
      "8     office city county denver open new tab window ...\n",
      "9     heading second term fed chair jerome powell bu...\n",
      "10    forbidden forbidden nginx delimit remark secre...\n",
      "11    joe manchin popularity west virginia soar bide...\n",
      "12    sinema backed bill protects strengthens invest...\n",
      "13    energy environment representative jared golden...\n",
      "14    adam kinzinger league conservation voter score...\n",
      "15    leading climate phil scott governor toggle nav...\n",
      "16    avoiding word climate change desantis say glob...\n",
      "17    resilience officer slate jacksonville climate ...\n",
      "18    mayor adam announces appointment climate leade...\n",
      "19    trump administration track record environment ...\n",
      "20    trump pick prominent climate skeptic epa chief...\n",
      "21    bully pulpit ted cruz offer take climate chang...\n",
      "22    senate mitch mcconnell admits human caused glo...\n",
      "23    jim jordan league conservation voter scorecard...\n",
      "24    lauren boebert forest management bill ignores ...\n",
      "25    governor abbott hold roundtable houston texas ...\n",
      "26    kristi noem believe climate change proven yout...\n",
      "27    alaska gop gov dunleavy disbands state climate...\n",
      "28    pdf obj endobj obj endobj obj extgstate xobjec...\n",
      "29    gov kate brown return international climate su...\n",
      "30    tackling climate crisis head elizabeth warren ...\n",
      "31    climate change continues increase cost disaste...\n",
      "32    solving climate crisis u senator brian schatz ...\n",
      "33    energy environment u senator richard blumentha...\n",
      "34    climate public land senator john hickenlooper ...\n",
      "35    cori bush steer funding fight climate crisis b...\n",
      "36    environment climate congressman ro khanna skip...\n",
      "37    environment energy policy america future jason...\n",
      "38    combating climate crisis adam schiff congress ...\n",
      "39    energy environment congresswoman nancy pelosi ...\n",
      "40    blackburn paris climate accord destroying amer...\n",
      "41    cotton demand answer blackrock involvement cli...\n",
      "42    republican sen rick scott talk infrastructure ...\n",
      "43    u senate site maintenance skip content website...\n",
      "44    lummis defends wyoming energy industry radical...\n",
      "45    se cupp marjorie taylor greene climate comment...\n",
      "46    javascript available detected javascript disab...\n",
      "47    lunar new deal gop rep gohmert suggests alteri...\n",
      "48    house minority leader kevin mccarthy unveil co...\n",
      "49    madison cawthorn moe davis climate change park...\n",
      "Name: corpus_cleaned, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(df['corpus_cleaned'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b2ed05a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44986\n"
     ]
    }
   ],
   "source": [
    "# Get size of dictionary for one-hot encoding\n",
    "results = set()\n",
    "df['corpus_cleaned'].str.lower().str.split().apply(results.update)\n",
    "vocab_size = len(results)\n",
    "print(vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "003a2977",
   "metadata": {},
   "outputs": [],
   "source": [
    "lb_make = LabelEncoder()\n",
    "\n",
    "labels = lb_make.fit_transform(df['label'])\n",
    "corpora = df['corpus_cleaned']\n",
    "\n",
    "x_train, x_test , y_train, y_test = train_test_split(corpora, labels , test_size = 0.25)\n",
    "y_train = to_categorical(y_train, 3)\n",
    "y_test = to_categorical(y_test, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d649e191",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = [one_hot(d, vocab_size,filters='!\"#$%&()*+,-./:;<=>?@[\\]^_`{|}~',lower=True, split=' ') for d in x_train]\n",
    "x_test = [one_hot(d, vocab_size,filters='!\"#$%&()*+,-./:;<=>?@[\\]^_`{|}~',lower=True, split=' ') for d in x_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7d6fcba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length = 50000\n",
    "x_train = pad_sequences(x_train, max_length, padding='post')\n",
    "x_test = pad_sequences(x_test, max_length, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b42eac9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_2 (Embedding)     (None, 50000, 16)         719776    \n",
      "                                                                 \n",
      " conv1d_2 (Conv1D)           (None, 49996, 32)         2592      \n",
      "                                                                 \n",
      " average_pooling1d_2 (Averag  (None, 24998, 32)        0         \n",
      " ePooling1D)                                                     \n",
      "                                                                 \n",
      " flatten_2 (Flatten)         (None, 799936)            0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 250)               199984250 \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 100)               25100     \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 16)                1616      \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 3)                 51        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 200,733,385\n",
      "Trainable params: 200,733,385\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=vocab_size, output_dim=16, input_length=max_length))\n",
    "model.add(Conv1D(32, 5, activation='relu', input_shape=(5000,16)))\n",
    "model.add(AveragePooling1D())\n",
    "model.add(Flatten())\n",
    "model.add(Dense(250, activation='relu'))\n",
    "model.add(Dense(100, activation='relu'))\n",
    "model.add(Dense(16, activation='relu'))\n",
    "model.add(Dense(3, activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "42e2ad7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-08 08:31:59.261632: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 - 13s - loss: 1.4608 - accuracy: 0.1892 - val_loss: 1.5055 - val_accuracy: 0.3846 - 13s/epoch - 6s/step\n",
      "Epoch 2/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-08 08:32:11.225672: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 - 11s - loss: 1.2790 - accuracy: 0.4324 - val_loss: 1.1811 - val_accuracy: 0.2308 - 11s/epoch - 6s/step\n",
      "Epoch 3/5\n",
      "2/2 - 9s - loss: 1.1621 - accuracy: 0.2703 - val_loss: 1.0827 - val_accuracy: 0.4615 - 9s/epoch - 5s/step\n",
      "Epoch 4/5\n",
      "2/2 - 1s - loss: 1.0794 - accuracy: 0.4054 - val_loss: 1.0883 - val_accuracy: 0.4615 - 1s/epoch - 702ms/step\n",
      "Epoch 5/5\n",
      "2/2 - 1s - loss: 1.0729 - accuracy: 0.4054 - val_loss: 1.0889 - val_accuracy: 0.4615 - 1s/epoch - 748ms/step\n",
      "Accuracy: 46.15%\n"
     ]
    }
   ],
   "source": [
    "model.fit(x_train, y_train, validation_data=(x_test, y_test), epochs=5, batch_size=30, verbose=2)\n",
    "# Getting score metrics from our model\n",
    "scores = model.evaluate(x_test, y_test, verbose=0)\n",
    "# Displays the accuracy of correct sentiment prediction over test data\n",
    "print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:mlp] *",
   "language": "python",
   "name": "conda-env-mlp-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
